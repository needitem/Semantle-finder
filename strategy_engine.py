#!/usr/bin/env python3
"""
ì „ëµ ì—”ì§„ ëª¨ë“ˆ
4ë‹¨ê³„ ì ì‘í˜• íƒìƒ‰ ì „ëµì„ êµ¬í˜„í•˜ëŠ” ëª¨ë“ˆì…ë‹ˆë‹¤.
"""

import random
from typing import List, Dict, Set, Optional, Tuple
from abc import ABC, abstractmethod

from models import GuessResult, GameSession


class SearchStrategy(ABC):
    """
    íƒìƒ‰ ì „ëµì˜ ì¶”ìƒ ê¸°ë³¸ í´ë˜ìŠ¤
    ëª¨ë“  êµ¬ì²´ì ì¸ ì „ëµë“¤ì´ ìƒì†ë°›ì•„ì•¼ í•˜ëŠ” ì¸í„°í˜ì´ìŠ¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.
    """
    
    @abstractmethod
    def select_word(self, session: GameSession, vocab: List[str], 
                   learned_data: Dict) -> Optional[str]:
        """
        ì „ëµì— ë”°ë¼ ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.
        
        Args:
            session (GameSession): í˜„ì¬ ê²Œì„ ì„¸ì…˜
            vocab (List[str]): ì‚¬ìš© ê°€ëŠ¥í•œ ì–´íœ˜ ëª©ë¡
            learned_data (Dict): í•™ìŠµëœ ë°ì´í„°
            
        Returns:
            Optional[str]: ì„ íƒëœ ë‹¨ì–´ (ì—†ìœ¼ë©´ None)
        """
        pass
    
    @abstractmethod
    def get_strategy_name(self) -> str:
        """ì „ëµ ì´ë¦„ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        pass


class WideSemanticExploration(SearchStrategy):
    """
    1ë‹¨ê³„: ë„“ì€ ì˜ë¯¸ íƒìƒ‰ ì „ëµ
    ë‹¤ì–‘í•œ ì˜ë¯¸ ì˜ì—­ì„ íƒìƒ‰í•˜ì—¬ ì´ˆê¸° ì•µì»¤ í¬ì¸íŠ¸ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
    """
    
    def __init__(self):
        """ì˜ë¯¸ ë²”ì£¼ë“¤ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        # 8ê°œì˜ í•µì‹¬ ì˜ë¯¸ ë²”ì£¼ ì •ì˜
        self.semantic_categories = {
            "ì¶”ìƒê°œë…": ["ìƒê°", "ë§ˆìŒ", "ì •ì‹ ", "ì˜ì‹", "ê°ì •", "ëŠë‚Œ"],
            "ë¬¼ë¦¬ê°ì²´": ["ì‚¬ë¬¼", "ë¬¼ê±´", "ë¬¼ì²´", "ì¡´ì¬", "ì‹¤ì²´", "í˜•íƒœ"],
            "ê´€ê³„ì—°ê²°": ["ê´€ê³„", "ì—°ê²°", "ê²°í•©", "ë§Œë‚¨", "ì†Œí†µ", "êµë¥˜"],
            "ë³€í™”ê³¼ì •": ["ë³€í™”", "ê³¼ì •", "ë°œì „", "ì„±ì¥", "ì§„í–‰", "íë¦„"],
            "ê³µê°„ìœ„ì¹˜": ["ê³µê°„", "ì¥ì†Œ", "ìœ„ì¹˜", "ì§€ì—­", "ì˜ì—­", "ë²”ìœ„"],
            "ì‹œê°„ìˆœì„œ": ["ì‹œê°„", "ìˆœê°„", "ì‹œê¸°", "ë•Œ", "ê¸°ê°„", "ìˆœì„œ"],
            "í–‰ë™í™œë™": ["í–‰ë™", "í™œë™", "ì›€ì§ì„", "ì‘ì—…", "ë…¸ë ¥", "ì‹¤í–‰"],
            "ìƒíƒœì¡°ê±´": ["ìƒíƒœ", "ì¡°ê±´", "ìƒí™©", "í™˜ê²½", "ë¶„ìœ„ê¸°", "ê¸°ë¶„"]
        }
    
    def select_word(self, session: GameSession, vocab: List[str], 
                   learned_data: Dict) -> Optional[str]:
        """
        ë‹¤ì–‘í•œ ì˜ë¯¸ ì˜ì—­ì—ì„œ ì•„ì§ ì‹œë„í•˜ì§€ ì•Šì€ ë‹¨ì–´ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.
        
        Args:
            session (GameSession): í˜„ì¬ ê²Œì„ ì„¸ì…˜
            vocab (List[str]): ì‚¬ìš© ê°€ëŠ¥í•œ ì–´íœ˜ ëª©ë¡
            learned_data (Dict): í•™ìŠµëœ ë°ì´í„°
            
        Returns:
            Optional[str]: ì„ íƒëœ ë‹¨ì–´
        """
        # ì²« ë²ˆì§¸ ì‹œë„ì¸ ê²½ìš° ì´ˆê¸° ë‹¤ì–‘ì„± ë‹¨ì–´ ì„ íƒ
        if not session.guesses:
            initial_words = ["ì‚¬ëŒ", "ì‹œê°„", "ì‚¬ë‘", "ìì—°", "ìŒì‹", "ê¸°ìˆ ", "ê°ì •", "ì¥ì†Œ", "í–‰ë™", "ìƒê°"]
            available_initial = [w for w in initial_words 
                               if w in vocab and w not in session.tried_words]
            if available_initial:
                return random.choice(available_initial)
        
        # ì´ë¯¸ ì‹œë„í•œ ì˜ë¯¸ ë²”ì£¼ë“¤ ì‹ë³„
        tried_categories = self._identify_tried_categories(session.guesses)
        
        # ì•„ì§ ì‹œë„í•˜ì§€ ì•Šì€ ë²”ì£¼ì—ì„œ ë‹¨ì–´ ì„ íƒ
        untried_categories = [cat for cat in self.semantic_categories.keys() 
                            if cat not in tried_categories]
        
        if untried_categories:
            # ìƒˆë¡œìš´ ë²”ì£¼ì—ì„œ ëœë¤ ì„ íƒ
            selected_category = random.choice(untried_categories)
            category_words = [w for w in self.semantic_categories[selected_category]
                            if w in vocab and w not in session.tried_words]
            
            if category_words:
                selected_word = random.choice(category_words)
                print(f"   ğŸ¯ ìƒˆë¡œìš´ ì˜ë¯¸ ì˜ì—­ '{selected_category}': '{selected_word}'")
                return selected_word
        
        # ëª¨ë“  ë²”ì£¼ë¥¼ ì‹œë„í–ˆë‹¤ë©´ íŒŒìƒì–´ íƒìƒ‰
        return self._explore_derivatives(session, vocab)
    
    def _identify_tried_categories(self, guesses: List[GuessResult]) -> Set[str]:
        """
        ì´ë¯¸ ì‹œë„í•œ ì˜ë¯¸ ë²”ì£¼ë“¤ì„ ì‹ë³„í•©ë‹ˆë‹¤.
        
        Args:
            guesses (List[GuessResult]): ì§€ê¸ˆê¹Œì§€ì˜ ì¶”ì¸¡ë“¤
            
        Returns:
            Set[str]: ì‹œë„í•œ ë²”ì£¼ë“¤ì˜ ì§‘í•©
        """
        tried_categories = set()
        
        for guess in guesses:
            for category_name, category_words in self.semantic_categories.items():
                if guess.word in category_words:
                    tried_categories.add(category_name)
        
        return tried_categories
    
    def _explore_derivatives(self, session: GameSession, vocab: List[str]) -> Optional[str]:
        """
        ê¸°ì¡´ ë‹¨ì–´ë“¤ì˜ íŒŒìƒì–´ë¥¼ íƒìƒ‰í•©ë‹ˆë‹¤.
        
        Args:
            session (GameSession): í˜„ì¬ ê²Œì„ ì„¸ì…˜
            vocab (List[str]): ì‚¬ìš© ê°€ëŠ¥í•œ ì–´íœ˜ ëª©ë¡
            
        Returns:
            Optional[str]: ì„ íƒëœ íŒŒìƒì–´
        """
        derivatives = []
        
        # ê¸°ì¡´ ì¶”ì¸¡ì—ì„œ ì–´ê·¼ ê¸°ë°˜ íŒŒìƒì–´ ìƒì„±
        for guess in session.guesses:
            word = guess.word
            if len(word) > 1:
                root = word[:-1]  # ë§ˆì§€ë§‰ ê¸€ì ì œê±°
                
                # ê°™ì€ ì–´ê·¼ì„ ê°€ì§„ ë‹¨ì–´ë“¤ ì°¾ê¸°
                for vocab_word in vocab:
                    if (vocab_word.startswith(root) and 
                        vocab_word != word and 
                        vocab_word not in session.tried_words and 
                        len(vocab_word) <= len(word) + 2):
                        
                        # ì˜ˆìƒ ìœ ì‚¬ë„ ì°¨ì´ ê³„ì‚° (ì‘ì„ìˆ˜ë¡ ì¢‹ìŒ)
                        expected_diff = abs(guess.similarity - 0.1)
                        derivatives.append((vocab_word, expected_diff))
        
        if derivatives:
            # ìœ ì‚¬ë„ê°€ ë†’ì„ ê²ƒìœ¼ë¡œ ì˜ˆìƒë˜ëŠ” ìˆœìœ¼ë¡œ ì •ë ¬
            derivatives.sort(key=lambda x: x[1])
            selected_word = derivatives[0][0]
            print(f"   ğŸ¯ íŒŒìƒì–´ íƒìƒ‰: '{selected_word}'")
            return selected_word
        
        # íŒŒìƒì–´ë„ ì—†ìœ¼ë©´ ëœë¤ ì„ íƒ
        available_words = [w for w in vocab if w not in session.tried_words]
        if available_words:
            return random.choice(available_words)
        
        return None
    
    def get_strategy_name(self) -> str:
        return "ë„“ì€ì˜ë¯¸íƒìƒ‰"


class SemanticGradientSearch(SearchStrategy):
    """
    2ë‹¨ê³„: ì˜ë¯¸ì  ê²½ì‚¬ íƒìƒ‰ ì „ëµ
    ê³ ì„±ëŠ¥ ì•µì»¤ ë‹¨ì–´ë“¤ì„ ê¸°ë°˜ìœ¼ë¡œ ì˜ë¯¸ì  ê²½ì‚¬ë¥¼ ë”°ë¼ íƒìƒ‰í•©ë‹ˆë‹¤.
    """
    
    def __init__(self):
        """ì˜ë¯¸ì  í™•ì¥ ê·œì¹™ë“¤ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        # ì–¸ì–´í•™ì  ì—°ê´€ì–´ ê·¸ë£¹
        self.linguistic_associations = {
            "ë¬¸ì œ": ["ê³¼ì œ", "ìŸì ", "ì´ìŠˆ", "ê³ ë¯¼", "ê±±ì •", "ë‚œì œ"],
            "í•´ê²°": ["ì²˜ë¦¬", "í•´ë‹µ", "ë°©ì•ˆ", "ëŒ€ì•ˆ", "ê·¹ë³µ", "ì™„ë£Œ"],
            "ì¤‘ìš”": ["í•µì‹¬", "ì£¼ìš”", "í•„ìˆ˜", "ê¸°ë³¸", "ê·¼ë³¸", "ë³¸ì§ˆ"],
            "ë³€í™”": ["ì „í™˜", "ê°œì„ ", "ë°œì „", "ì§„ë³´", "ì„±ì¥", "í˜ì‹ "],
            "ê´€ê³„": ["ì—°ê²°", "ê²°í•©", "ì†Œí†µ", "êµë¥˜", "ìƒí˜¸ì‘ìš©", "í˜‘ë ¥"]
        }
        
        # ë¬¸ë§¥ì  ê´€ë ¨ì–´ ë§¤í•‘
        self.contextual_maps = {
            # ì‚¬íšŒ/ì •ì¹˜ ë¬¸ë§¥
            "ì‚¬íšŒ": ["ì •ì¹˜", "ê²½ì œ", "ë¬¸í™”", "êµìœ¡", "ë³µì§€", "ì œë„"],
            "êµ­ë¯¼": ["ì‹œë¯¼", "ì£¼ë¯¼", "ì¸ë¯¼", "êµ­ê°€", "ì •ë¶€", "ê³µë™ì²´"],
            
            # êµìœ¡/í•™ìŠµ ë¬¸ë§¥
            "í•™ìŠµ": ["êµìœ¡", "ê³µë¶€", "ì—°êµ¬", "ì§€ì‹", "ì´í•´", "ìŠµë“"],
            "ì§€ì‹": ["ì •ë³´", "í•™ë¬¸", "ê²½í—˜", "ê¸°ìˆ ", "ëŠ¥ë ¥", "ì‹¤ë ¥"],
            
            # ê°ì •/ì‹¬ë¦¬ ë¬¸ë§¥
            "ê°ì •": ["ë§ˆìŒ", "ê¸°ë¶„", "ëŠë‚Œ", "ì •ì„œ", "ì‹¬ë¦¬", "ì˜ì‹"],
            "í–‰ë³µ": ["ê¸°ì¨", "ë§Œì¡±", "ì¦ê±°ì›€", "ì›ƒìŒ", "í‰í™”", "ì‚¬ë‘"]
        }
    
    def select_word(self, session: GameSession, vocab: List[str], 
                   learned_data: Dict) -> Optional[str]:
        """
        ìƒìœ„ ìœ ì‚¬ë„ ë‹¨ì–´ë“¤ì„ ê¸°ë°˜ìœ¼ë¡œ ì˜ë¯¸ì  ê²½ì‚¬ë¥¼ ë”°ë¼ íƒìƒ‰í•©ë‹ˆë‹¤.
        
        Args:
            session (GameSession): í˜„ì¬ ê²Œì„ ì„¸ì…˜
            vocab (List[str]): ì‚¬ìš© ê°€ëŠ¥í•œ ì–´íœ˜ ëª©ë¡
            learned_data (Dict): í•™ìŠµëœ ë°ì´í„°
            
        Returns:
            Optional[str]: ì„ íƒëœ ë‹¨ì–´
        """
        # ìƒìœ„ 3ê°œ ì¶”ì¸¡ ì„ íƒ
        top_guesses = session.get_top_guesses(3)
        
        # ì—¬ëŸ¬ ë°©í–¥ìœ¼ë¡œ ë™ì‹œ íƒìƒ‰
        all_candidates = []
        
        for guess in top_guesses:
            # 1. ì˜ë¯¸ì  í™•ì¥
            expansions = self._get_semantic_expansions(guess.word, vocab, session.tried_words)
            all_candidates.extend(expansions)
            
            # 2. ì—°ê´€ì–´ íƒìƒ‰
            associations = self._get_semantic_associations(guess.word, vocab, session.tried_words)
            all_candidates.extend(associations)
            
            # 3. ë¬¸ë§¥ì  ê´€ë ¨ì–´
            contextual = self._get_contextual_relations(guess.word, vocab, session.tried_words)
            all_candidates.extend(contextual)
        
        # ì¤‘ë³µ ì œê±° ë° í•™ìŠµëœ íš¨ê³¼ì„±ìœ¼ë¡œ ì •ë ¬
        unique_candidates = list(set(all_candidates))
        if unique_candidates:
            sorted_candidates = self._sort_by_effectiveness(
                unique_candidates, learned_data.get('word_frequency', {}))
            
            selected_word = sorted_candidates[0]
            print(f"   ğŸ¯ ì˜ë¯¸ì  ë°©í–¥ íƒìƒ‰: '{selected_word}'")
            return selected_word
        
        # í›„ë³´ê°€ ì—†ìœ¼ë©´ Wide íƒìƒ‰ìœ¼ë¡œ ë³µê·€
        wide_strategy = WideSemanticExploration()
        return wide_strategy.select_word(session, vocab, learned_data)
    
    def _get_semantic_expansions(self, word: str, vocab: List[str], 
                               tried_words: Set[str]) -> List[str]:
        """
        ë‹¨ì–´ì˜ ì˜ë¯¸ì  í™•ì¥ì–´ë“¤ì„ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            word (str): ê¸°ì¤€ ë‹¨ì–´
            vocab (List[str]): ì‚¬ìš© ê°€ëŠ¥í•œ ì–´íœ˜
            tried_words (Set[str]): ì´ë¯¸ ì‹œë„í•œ ë‹¨ì–´ë“¤
            
        Returns:
            List[str]: í™•ì¥ì–´ ëª©ë¡
        """
        expansions = []
        
        # ì–´ê·¼ ê¸°ë°˜ í™•ì¥ (ì• 2ê¸€ì ì–´ê·¼)
        if len(word) > 2:
            root = word[:2]
            for vocab_word in vocab:
                if (vocab_word.startswith(root) and 
                    vocab_word != word and 
                    vocab_word not in tried_words):
                    expansions.append(vocab_word)
        
        # ì˜ë¯¸ ì˜ì—­ë³„ í™•ì¥
        semantic_expansions = {
            "ì‚¬ëŒ": ["ì¸ê°„", "ê°œì¸", "íƒ€ì¸", "ëˆ„êµ°ê°€", "ì‚¬ëŒë“¤", "ì¸ë¬¼", "ì¸ì‚¬"],
            "ì‹œê°„": ["ë•Œ", "ìˆœê°„", "ì‹œê¸°", "ì‹œì ˆ", "ê¸°ê°„", "ì‹œì ", "ì‹œëŒ€"],
            "ì¥ì†Œ": ["ê³³", "ì§€ì—­", "ìœ„ì¹˜", "ê³µê°„", "ì˜ì—­", "ë²”ìœ„", "ì˜í† "],
            "ë°©ë²•": ["ìˆ˜ë‹¨", "ë°©ì‹", "ê¸°ë²•", "ì ˆì°¨", "ê³¼ì •", "ë‹¨ê³„"],
            "ìƒíƒœ": ["ì¡°ê±´", "ìƒí™©", "í™˜ê²½", "ë¶„ìœ„ê¸°", "ëŠë‚Œ", "ê¸°ë¶„"],
            "í–‰ë™": ["í™œë™", "ì›€ì§ì„", "ì‘ì—…", "í–‰ìœ„", "ì‹¤í–‰", "ì§„í–‰"]
        }
        
        # í•´ë‹¹ ë²”ì£¼ì— ì†í•˜ëŠ” ê²½ìš° ê°™ì€ ë²”ì£¼ì˜ ë‹¤ë¥¸ ë‹¨ì–´ë“¤ ì¶”ê°€
        for category, words in semantic_expansions.items():
            if word in words:
                for expansion_word in words:
                    if (expansion_word != word and 
                        expansion_word in vocab and 
                        expansion_word not in tried_words):
                        expansions.append(expansion_word)
        
        return expansions[:10]  # ìµœëŒ€ 10ê°œë¡œ ì œí•œ
    
    def _get_semantic_associations(self, word: str, vocab: List[str], 
                                 tried_words: Set[str]) -> List[str]:
        """
        ë‹¨ì–´ì˜ ì˜ë¯¸ì  ì—°ê´€ì–´ë“¤ì„ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            word (str): ê¸°ì¤€ ë‹¨ì–´
            vocab (List[str]): ì‚¬ìš© ê°€ëŠ¥í•œ ì–´íœ˜
            tried_words (Set[str]): ì´ë¯¸ ì‹œë„í•œ ë‹¨ì–´ë“¤
            
        Returns:
            List[str]: ì—°ê´€ì–´ ëª©ë¡
        """
        associations = []
        
        # ì–¸ì–´í•™ì  ì—°ê´€ì–´ ê²€ìƒ‰
        for key, words in self.linguistic_associations.items():
            if word == key or word in words:
                for assoc_word in words:
                    if (assoc_word != word and 
                        assoc_word in vocab and 
                        assoc_word not in tried_words):
                        associations.append(assoc_word)
        
        return associations[:8]  # ìµœëŒ€ 8ê°œë¡œ ì œí•œ
    
    def _get_contextual_relations(self, word: str, vocab: List[str], 
                                tried_words: Set[str]) -> List[str]:
        """
        ë‹¨ì–´ì˜ ë¬¸ë§¥ì  ê´€ë ¨ì–´ë“¤ì„ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            word (str): ê¸°ì¤€ ë‹¨ì–´
            vocab (List[str]): ì‚¬ìš© ê°€ëŠ¥í•œ ì–´íœ˜
            tried_words (Set[str]): ì´ë¯¸ ì‹œë„í•œ ë‹¨ì–´ë“¤
            
        Returns:
            List[str]: ë¬¸ë§¥ì  ê´€ë ¨ì–´ ëª©ë¡
        """
        relations = []
        
        # ë¬¸ë§¥ì  ê´€ë ¨ì–´ ê²€ìƒ‰
        for key, words in self.contextual_maps.items():
            if word == key or word in words:
                for rel_word in words:
                    if (rel_word != word and 
                        rel_word in vocab and 
                        rel_word not in tried_words):
                        relations.append(rel_word)
        
        return relations[:6]  # ìµœëŒ€ 6ê°œë¡œ ì œí•œ
    
    def _sort_by_effectiveness(self, candidates: List[str], 
                             word_frequency: Dict) -> List[str]:
        """
        í•™ìŠµëœ íš¨ê³¼ì„±ì— ë”°ë¼ í›„ë³´ë“¤ì„ ì •ë ¬í•©ë‹ˆë‹¤.
        
        Args:
            candidates (List[str]): í›„ë³´ ë‹¨ì–´ë“¤
            word_frequency (Dict): ë‹¨ì–´ ë¹ˆë„ ë°ì´í„°
            
        Returns:
            List[str]: íš¨ê³¼ì„± ìˆœìœ¼ë¡œ ì •ë ¬ëœ í›„ë³´ë“¤
        """
        def get_effectiveness_score(word: str) -> float:
            if word in word_frequency:
                freq_data = word_frequency[word]
                return freq_data.get('avg_similarity', 0) * freq_data.get('count', 1)
            return 0
        
        candidates.sort(key=get_effectiveness_score, reverse=True)
        return candidates
    
    def get_strategy_name(self) -> str:
        return "ì˜ë¯¸ì ê²½ì‚¬íƒìƒ‰"


class FocusedSemanticSearch(SearchStrategy):
    """
    3ë‹¨ê³„: ì§‘ì¤‘ ì˜ë¯¸ íƒìƒ‰ ì „ëµ
    ê³ ìœ ì‚¬ë„ ì˜ì—­ ì£¼ë³€ì—ì„œ ë‹¤ì¸µ ì—°ê´€ì„ ì‚¬ìš©í•˜ì—¬ ì§‘ì¤‘ì ìœ¼ë¡œ íƒìƒ‰í•©ë‹ˆë‹¤.
    """
    
    def __init__(self):
        """ì˜ë¯¸ ì˜ì—­ë³„ ë‹¨ì–´ ê·¸ë£¹ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        self.semantic_fields = {
            "ì •ì¹˜ì‚¬íšŒ": ["ì •ì¹˜", "ì‚¬íšŒ", "êµ­ê°€", "ì •ë¶€", "êµ­ë¯¼", "ì‹œë¯¼", "ê³µë™ì²´", "ì‚¬íšŒì ", "ì •ì±…", "ì œë„"],
            "êµìœ¡í•™ìŠµ": ["êµìœ¡", "í•™ìŠµ", "ê³µë¶€", "ì§€ì‹", "í•™ë¬¸", "ì—°êµ¬", "ì´í•´", "ìŠµë“", "ê²½í—˜"],
            "ê°ì •ì‹¬ë¦¬": ["ê°ì •", "ë§ˆìŒ", "ê¸°ë¶„", "ëŠë‚Œ", "ì •ì„œ", "ì‹¬ë¦¬", "ì‚¬ë‘", "í–‰ë³µ", "ìŠ¬í””"],
            "ì‹œê³µê°„": ["ì‹œê°„", "ê³µê°„", "ì¥ì†Œ", "ìœ„ì¹˜", "ë•Œ", "ìˆœê°„", "ì§€ì—­", "ì˜ì—­", "ë²”ìœ„"],
            "í–‰ë™í™œë™": ["í–‰ë™", "í™œë™", "ì›€ì§ì„", "ì‘ì—…", "ì‹¤í–‰", "ì§„í–‰", "ê³¼ì •", "ë°©ë²•"]
        }
    
    def select_word(self, session: GameSession, vocab: List[str], 
                   learned_data: Dict) -> Optional[str]:
        """
        ê³ ìœ ì‚¬ë„ ë‹¨ì–´ë“¤ì˜ ê³µí†µ ì˜ë¯¸ ì˜ì—­ì—ì„œ ì§‘ì¤‘ì ìœ¼ë¡œ íƒìƒ‰í•©ë‹ˆë‹¤.
        
        Args:
            session (GameSession): í˜„ì¬ ê²Œì„ ì„¸ì…˜
            vocab (List[str]): ì‚¬ìš© ê°€ëŠ¥í•œ ì–´íœ˜ ëª©ë¡
            learned_data (Dict): í•™ìŠµëœ ë°ì´í„°
            
        Returns:
            Optional[str]: ì„ íƒëœ ë‹¨ì–´
        """
        # ìƒìœ„ 2ê°œ ì¶”ì¸¡ ë¶„ì„
        top_guesses = session.get_top_guesses(2)
        
        # ê³µí†µ ì˜ë¯¸ ì˜ì—­ ì°¾ê¸°
        common_field = self._find_common_semantic_field([g.word for g in top_guesses])
        
        if common_field:
            candidates = [w for w in common_field 
                         if w in vocab and w not in session.tried_words]
            if candidates:
                selected_word = candidates[0]
                print(f"   ğŸ¯ ê³µí†µ ì˜ë¯¸ ì˜ì—­: '{selected_word}'")
                return selected_word
        
        # ìµœê³  ë‹¨ì–´ ì£¼ë³€ ë‹¤ì¸µ íƒìƒ‰
        if session.guesses:
            best_guess = max(session.guesses, key=lambda g: g.similarity)
            
            # 1ì¸µ: ì§ì ‘ ì—°ê´€ì–´
            gradient_strategy = SemanticGradientSearch()
            layer1 = gradient_strategy._get_semantic_associations(
                best_guess.word, vocab, session.tried_words)
            
            # 2ì¸µ: 1ì¸µ ë‹¨ì–´ë“¤ì˜ ì—°ê´€ì–´
            layer2 = []
            for word in layer1[:3]:  # ìƒìœ„ 3ê°œë§Œ
                if word not in session.tried_words:
                    layer2.extend(gradient_strategy._get_semantic_associations(
                        word, vocab, session.tried_words))
            
            # ëª¨ë“  í›„ë³´ ê²°í•©
            all_candidates = layer1 + layer2
            unique_candidates = [w for w in set(all_candidates) 
                               if w in vocab and w not in session.tried_words]
            
            if unique_candidates:
                # íš¨ê³¼ì„±ìœ¼ë¡œ ì •ë ¬
                sorted_candidates = gradient_strategy._sort_by_effectiveness(
                    unique_candidates, learned_data.get('word_frequency', {}))
                
                selected_word = sorted_candidates[0]
                print(f"   ğŸ¯ '{best_guess.word}' ë‹¤ì¸µ ì—°ê´€ì–´: '{selected_word}'")
                return selected_word
        
        # ì‹¤íŒ¨ ì‹œ ê²½ì‚¬ íƒìƒ‰ìœ¼ë¡œ ë³µê·€
        gradient_strategy = SemanticGradientSearch()
        return gradient_strategy.select_word(session, vocab, learned_data)
    
    def _find_common_semantic_field(self, words: List[str]) -> List[str]:
        """
        ë‹¨ì–´ë“¤ì˜ ê³µí†µ ì˜ë¯¸ ì˜ì—­ì„ ì°¾ìŠµë‹ˆë‹¤.
        
        Args:
            words (List[str]): ë¶„ì„í•  ë‹¨ì–´ë“¤
            
        Returns:
            List[str]: ê³µí†µ ì˜ë¯¸ ì˜ì—­ì˜ ë‹¨ì–´ë“¤
        """
        if len(words) < 2:
            return []
        
        # ëª¨ë“  ë‹¨ì–´ê°€ ì†í•˜ëŠ” ì˜ë¯¸ ì˜ì—­ ì°¾ê¸°
        for field_name, field_words in self.semantic_fields.items():
            # ëª¨ë“  ì…ë ¥ ë‹¨ì–´ê°€ ì´ ì˜ì—­ì— ì†í•˜ëŠ”ì§€ í™•ì¸
            if all(any(word in field_words or word.startswith(fw[:2]) 
                      for fw in field_words) for word in words):
                # ì…ë ¥ ë‹¨ì–´ë“¤ì„ ì œì™¸í•œ ë‚˜ë¨¸ì§€ ë°˜í™˜
                return [w for w in field_words if w not in words]
        
        return []
    
    def get_strategy_name(self) -> str:
        return "ì§‘ì¤‘ì˜ë¯¸íƒìƒ‰"


class PrecisionSemanticSearch(SearchStrategy):
    """
    4ë‹¨ê³„: ì •ë°€ ì˜ë¯¸ íƒìƒ‰ ì „ëµ
    í˜•íƒœë¡ ì  ë¶„ì„ì„ ì‚¬ìš©í•˜ì—¬ ê³ ìœ ì‚¬ë„ ìƒí™©ì—ì„œ ì •ë°€í•˜ê²Œ íƒìƒ‰í•©ë‹ˆë‹¤.
    """
    
    def select_word(self, session: GameSession, vocab: List[str], 
                   learned_data: Dict) -> Optional[str]:
        """
        í˜•íƒœë¡ ì  ë³€í˜•ê³¼ í•™ìŠµëœ ì´ˆê·¼ì ‘ ë‹¨ì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì •ë°€ íƒìƒ‰í•©ë‹ˆë‹¤.
        
        Args:
            session (GameSession): í˜„ì¬ ê²Œì„ ì„¸ì…˜
            vocab (List[str]): ì‚¬ìš© ê°€ëŠ¥í•œ ì–´íœ˜ ëª©ë¡
            learned_data (Dict): í•™ìŠµëœ ë°ì´í„°
            
        Returns:
            Optional[str]: ì„ íƒëœ ë‹¨ì–´
        """
        if not session.guesses:
            return None
        
        best_guess = max(session.guesses, key=lambda g: g.similarity)
        precision_candidates = []
        
        # 1. í˜•íƒœë¡ ì  ë³€í˜• ìƒì„±
        morphological_variants = self._generate_morphological_variants(
            best_guess.word, vocab, session.tried_words)
        precision_candidates.extend(morphological_variants[:3])
        
        # 2. í•™ìŠµëœ ì´ˆê·¼ì ‘ ë‹¨ì–´ë“¤
        word_pairs = learned_data.get('word_pairs', {})
        ultra_close_words = self._find_ultra_close_words(
            best_guess.word, word_pairs, vocab, session.tried_words)
        precision_candidates.extend([w[0] for w in ultra_close_words[:2]])
        
        if precision_candidates:
            selected_word = precision_candidates[0]
            print(f"   ğŸ¯ '{best_guess.word}' ì •ë°€ ë³€í˜•: '{selected_word}'")
            return selected_word
        
        # ì •ë°€ íƒìƒ‰ ì‹¤íŒ¨ ì‹œ ì§‘ì¤‘ íƒìƒ‰ìœ¼ë¡œ ë³µê·€
        focused_strategy = FocusedSemanticSearch()
        return focused_strategy.select_word(session, vocab, learned_data)
    
    def _generate_morphological_variants(self, word: str, vocab: List[str], 
                                       tried_words: Set[str]) -> List[str]:
        """
        ë‹¨ì–´ì˜ í˜•íƒœë¡ ì  ë³€í˜•ë“¤ì„ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            word (str): ê¸°ì¤€ ë‹¨ì–´
            vocab (List[str]): ì‚¬ìš© ê°€ëŠ¥í•œ ì–´íœ˜
            tried_words (Set[str]): ì´ë¯¸ ì‹œë„í•œ ë‹¨ì–´ë“¤
            
        Returns:
            List[str]: í˜•íƒœë¡ ì  ë³€í˜•ë“¤
        """
        variants = []
        
        if len(word) > 2:
            root = word[:-1]  # ë§ˆì§€ë§‰ ê¸€ì ì œê±°
            
            # í•œêµ­ì–´ ì¼ë°˜ì ì¸ ì ‘ë¯¸ì‚¬ë“¤
            suffixes = ['ë‹¤', 'í•˜ë‹¤', 'ë˜ë‹¤', 'ì´ë‹¤', 'ì ', 'ì˜', 'ë¡œ', 'ì„', 'ë¥¼']
            
            for suffix in suffixes:
                variant = root + suffix
                if (variant in vocab and 
                    variant not in tried_words and 
                    variant != word):
                    variants.append(variant)
        
        return variants
    
    def _find_ultra_close_words(self, word: str, word_pairs: Dict, 
                              vocab: List[str], tried_words: Set[str]) -> List[Tuple[str, float]]:
        """
        í•™ìŠµëœ ë°ì´í„°ì—ì„œ ì´ˆê·¼ì ‘ ë‹¨ì–´ë“¤ì„ ì°¾ìŠµë‹ˆë‹¤.
        
        Args:
            word (str): ê¸°ì¤€ ë‹¨ì–´
            word_pairs (Dict): ë‹¨ì–´ ìŒ ë°ì´í„°
            vocab (List[str]): ì‚¬ìš© ê°€ëŠ¥í•œ ì–´íœ˜
            tried_words (Set[str]): ì´ë¯¸ ì‹œë„í•œ ë‹¨ì–´ë“¤
            
        Returns:
            List[Tuple[str, float]]: (ë‹¨ì–´, í‰ê· ì°¨ì´) íŠœí”Œì˜ ë¦¬ìŠ¤íŠ¸
        """
        ultra_close = []
        
        for pair_key, pair_data in word_pairs.items():
            word1, word2 = pair_key.split('|')
            
            if word1 == word or word2 == word:
                other_word = word2 if word1 == word else word1
                
                if (other_word in vocab and 
                    other_word not in tried_words):
                    
                    # í‰ê·  ìœ ì‚¬ë„ ì°¨ì´ ê³„ì‚°
                    similarity_diffs = pair_data.get('similarity_diffs', [])
                    if similarity_diffs:
                        avg_diff = sum(similarity_diffs) / len(similarity_diffs)
                        # ë§¤ìš° ìœ ì‚¬í•œ ë‹¨ì–´ë“¤ë§Œ (ì°¨ì´ < 0.03)
                        if avg_diff < 0.03:
                            ultra_close.append((other_word, avg_diff))
        
        # ìœ ì‚¬ë„ ì°¨ì´ ìˆœìœ¼ë¡œ ì •ë ¬ (ì‘ì€ ìˆœ)
        ultra_close.sort(key=lambda x: x[1])
        return ultra_close
    
    def get_strategy_name(self) -> str:
        return "ì •ë°€ì˜ë¯¸íƒìƒ‰"


class StrategyEngine:
    """
    ì „ëµ ì—”ì§„: ìƒí™©ì— ë”°ë¼ ì ì ˆí•œ íƒìƒ‰ ì „ëµì„ ì„ íƒí•˜ê³  ì‹¤í–‰í•©ë‹ˆë‹¤.
    """
    
    def __init__(self):
        """ëª¨ë“  ì „ëµë“¤ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        self.strategies = {
            "wide": WideSemanticExploration(),
            "gradient": SemanticGradientSearch(),
            "focused": FocusedSemanticSearch(),
            "precision": PrecisionSemanticSearch()
        }
    
    def select_strategy(self, session: GameSession) -> SearchStrategy:
        """
        í˜„ì¬ ìƒí™©ì— ë”°ë¼ ìµœì ì˜ ì „ëµì„ ì„ íƒí•©ë‹ˆë‹¤.
        
        Args:
            session (GameSession): í˜„ì¬ ê²Œì„ ì„¸ì…˜
            
        Returns:
            SearchStrategy: ì„ íƒëœ ì „ëµ ê°ì²´
        """
        best_similarity = session.get_best_similarity()
        is_stuck = session.is_stagnant()
        
        # 4ë‹¨ê³„ ì ì‘í˜• ì „ëµ ì„ íƒ
        if best_similarity < 0.1:
            strategy = self.strategies["wide"]
        elif best_similarity < 0.25 or is_stuck:
            if is_stuck:
                print("   âš ï¸ ì •ì²´ ìƒíƒœ - ì˜ë¯¸ ê³µê°„ í™•ì¥ íƒìƒ‰")
            strategy = self.strategies["gradient"]
        elif best_similarity < 0.5:
            strategy = self.strategies["focused"]
        else:
            strategy = self.strategies["precision"]
        
        # ì „ëµ ì´ë¦„ ì¶œë ¥
        print(f"   ğŸ“ˆ {strategy.get_strategy_name()}")
        
        return strategy
    
    def select_next_word(self, session: GameSession, vocab: List[str], 
                        learned_data: Dict) -> Optional[str]:
        """
        ìƒí™©ì— ë§ëŠ” ì „ëµì„ ì„ íƒí•˜ê³  ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.
        
        Args:
            session (GameSession): í˜„ì¬ ê²Œì„ ì„¸ì…˜
            vocab (List[str]): ì‚¬ìš© ê°€ëŠ¥í•œ ì–´íœ˜ ëª©ë¡
            learned_data (Dict): í•™ìŠµëœ ë°ì´í„°
            
        Returns:
            Optional[str]: ì„ íƒëœ ë‹¨ì–´
        """
        strategy = self.select_strategy(session)
        session.update_strategy(strategy.get_strategy_name())
        
        return strategy.select_word(session, vocab, learned_data)