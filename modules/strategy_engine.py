#!/usr/bin/env python3
"""
ì „ëµ ì—”ì§„ ëª¨ë“ˆ
4ë‹¨ê³„ ì ì‘í˜• íƒìƒ‰ ì „ëµì„ êµ¬í˜„í•˜ëŠ” ëª¨ë“ˆì…ë‹ˆë‹¤.
"""

import random
import math
from typing import List, Dict, Set, Optional, Tuple
from abc import ABC, abstractmethod
from collections import defaultdict

from .models import GuessResult, GameSession
from .strategy_logger import StrategyLogger


class SearchStrategy(ABC):
    """
    íƒìƒ‰ ì „ëµì˜ ì¶”ìƒ ê¸°ë³¸ í´ë˜ìŠ¤
    ëª¨ë“  êµ¬ì²´ì ì¸ ì „ëµë“¤ì´ ìƒì†ë°›ì•„ì•¼ í•˜ëŠ” ì¸í„°í˜ì´ìŠ¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.
    """
    
    @abstractmethod
    def select_word(self, session: GameSession, vocab: List[str], 
                   learned_data: Dict) -> Optional[str]:
        """
        ì „ëµì— ë”°ë¼ ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.
        
        Args:
            session (GameSession): í˜„ì¬ ê²Œì„ ì„¸ì…˜
            vocab (List[str]): ì‚¬ìš© ê°€ëŠ¥í•œ ì–´íœ˜ ëª©ë¡
            learned_data (Dict): í•™ìŠµëœ ë°ì´í„°
            
        Returns:
            Optional[str]: ì„ íƒëœ ë‹¨ì–´ (ì—†ìœ¼ë©´ None)
        """
        pass
    
    @abstractmethod
    def get_strategy_name(self) -> str:
        """ì „ëµ ì´ë¦„ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        pass


class WideSemanticExploration(SearchStrategy):
    """
    1ë‹¨ê³„: ë„“ì€ ì˜ë¯¸ íƒìƒ‰ ì „ëµ
    ë‹¤ì–‘í•œ ì˜ë¯¸ ì˜ì—­ì„ íƒìƒ‰í•˜ì—¬ ì´ˆê¸° ì•µì»¤ í¬ì¸íŠ¸ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
    """
    
    def __init__(self):
        """ì˜ë¯¸ ë²”ì£¼ë“¤ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        # 8ê°œì˜ í•µì‹¬ ì˜ë¯¸ ë²”ì£¼ ì •ì˜
        self.semantic_categories = {
            "ì¶”ìƒê°œë…": ["ìƒê°", "ë§ˆìŒ", "ì •ì‹ ", "ì˜ì‹", "ê°ì •", "ëŠë‚Œ"],
            "ë¬¼ë¦¬ê°ì²´": ["ì‚¬ë¬¼", "ë¬¼ê±´", "ë¬¼ì²´", "ì¡´ì¬", "ì‹¤ì²´", "í˜•íƒœ"],
            "ê´€ê³„ì—°ê²°": ["ê´€ê³„", "ì—°ê²°", "ê²°í•©", "ë§Œë‚¨", "ì†Œí†µ", "êµë¥˜"],
            "ë³€í™”ê³¼ì •": ["ë³€í™”", "ê³¼ì •", "ë°œì „", "ì„±ì¥", "ì§„í–‰", "íë¦„"],
            "ê³µê°„ìœ„ì¹˜": ["ê³µê°„", "ì¥ì†Œ", "ìœ„ì¹˜", "ì§€ì—­", "ì˜ì—­", "ë²”ìœ„"],
            "ì‹œê°„ìˆœì„œ": ["ì‹œê°„", "ìˆœê°„", "ì‹œê¸°", "ë•Œ", "ê¸°ê°„", "ìˆœì„œ"],
            "í–‰ë™í™œë™": ["í–‰ë™", "í™œë™", "ì›€ì§ì„", "ì‘ì—…", "ë…¸ë ¥", "ì‹¤í–‰"],
            "ìƒíƒœì¡°ê±´": ["ìƒíƒœ", "ì¡°ê±´", "ìƒí™©", "í™˜ê²½", "ë¶„ìœ„ê¸°", "ê¸°ë¶„"]
        }
    
    def select_word(self, session: GameSession, vocab: List[str], 
                   learned_data: Dict) -> Optional[str]:
        """
        ë‹¤ì–‘í•œ ì˜ë¯¸ ì˜ì—­ì—ì„œ ì•„ì§ ì‹œë„í•˜ì§€ ì•Šì€ ë‹¨ì–´ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.
        
        Args:
            session (GameSession): í˜„ì¬ ê²Œì„ ì„¸ì…˜
            vocab (List[str]): ì‚¬ìš© ê°€ëŠ¥í•œ ì–´íœ˜ ëª©ë¡
            learned_data (Dict): í•™ìŠµëœ ë°ì´í„°
            
        Returns:
            Optional[str]: ì„ íƒëœ ë‹¨ì–´
        """
        # ì²« ë²ˆì§¸ ì‹œë„ì¸ ê²½ìš° í•™ìŠµ ë°ì´í„° ê¸°ë°˜ ì´ˆê¸° ë‹¨ì–´ ì„ íƒ
        if not session.guesses:
            return self._select_initial_word(vocab, learned_data, session.tried_words)
        
        # ì´ë¯¸ ì‹œë„í•œ ì˜ë¯¸ ë²”ì£¼ë“¤ ì‹ë³„
        tried_categories = self._identify_tried_categories(session.guesses)
        
        # ë¨¼ì € í•™ìŠµ ë°ì´í„° ê¸°ë°˜ í›„ë³´ í™•ì¸
        learning_candidates = self._get_learning_based_candidates(vocab, learned_data, session.tried_words, 5)
        if learning_candidates:
            selected_word = learning_candidates[0]
            print(f"   ğŸ¯ í•™ìŠµ ê¸°ë°˜ ì„ íƒ: '{selected_word}'")
            return selected_word
        
        # ì•„ì§ ì‹œë„í•˜ì§€ ì•Šì€ ë²”ì£¼ì—ì„œ ë‹¨ì–´ ì„ íƒ
        untried_categories = [cat for cat in self.semantic_categories.keys() 
                            if cat not in tried_categories]
        
        if untried_categories:
            # ìƒˆë¡œìš´ ë²”ì£¼ì—ì„œ ëœë¤ ì„ íƒ
            selected_category = random.choice(untried_categories)
            category_words = [w for w in self.semantic_categories[selected_category]
                            if w in vocab and w not in session.tried_words]
            
            if category_words:
                selected_word = random.choice(category_words)
                print(f"   ğŸ¯ ìƒˆë¡œìš´ ì˜ë¯¸ ì˜ì—­ '{selected_category}': '{selected_word}'")
                return selected_word
        
        # ëª¨ë“  ë²”ì£¼ë¥¼ ì‹œë„í–ˆë‹¤ë©´ íŒŒìƒì–´ íƒìƒ‰
        return self._explore_derivatives(session, vocab)
    
    def _identify_tried_categories(self, guesses: List[GuessResult]) -> Set[str]:
        """
        ì´ë¯¸ ì‹œë„í•œ ì˜ë¯¸ ë²”ì£¼ë“¤ì„ ì‹ë³„í•©ë‹ˆë‹¤.
        
        Args:
            guesses (List[GuessResult]): ì§€ê¸ˆê¹Œì§€ì˜ ì¶”ì¸¡ë“¤
            
        Returns:
            Set[str]: ì‹œë„í•œ ë²”ì£¼ë“¤ì˜ ì§‘í•©
        """
        tried_categories = set()
        
        for guess in guesses:
            for category_name, category_words in self.semantic_categories.items():
                if guess.word in category_words:
                    tried_categories.add(category_name)
        
        return tried_categories
    
    def _select_initial_word(self, vocab: List[str], learned_data: Dict, 
                           tried_words: Set[str]) -> Optional[str]:
        """
        í•™ìŠµ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ íš¨ê³¼ì ì¸ ì´ˆê¸° ë‹¨ì–´ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.
        
        Args:
            vocab (List[str]): ì‚¬ìš© ê°€ëŠ¥í•œ ì–´íœ˜ ëª©ë¡
            learned_data (Dict): í•™ìŠµëœ ë°ì´í„°
            tried_words (Set[str]): ì´ë¯¸ ì‹œë„í•œ ë‹¨ì–´ë“¤
            
        Returns:
            Optional[str]: ì„ íƒëœ ì´ˆê¸° ë‹¨ì–´
        """
        word_frequency = learned_data.get('word_frequency', {})
        
        # ì´ˆê¸° ë‹¨ì–´ í›„ë³´ë“¤ì— ì ìˆ˜ ë¶€ì—¬ (ë¡œê·¸ ë¶„ì„ ê²°ê³¼ ë°˜ì˜)
        initial_candidates = []
        # ê³ ì˜í–¥ ë‹¨ì–´ë“¤ì„ ìš°ì„  ì¶”ê°€
        high_impact_words = ["ì‚¬ë¡€", "ì‹¤íŒ¨", "ê¸°ì›", "ë°©ë²•", "ê¸°ì—…", "ì‚¬ì—…", "ê³µë¶€", "ê¸°ìˆ ", "ë°©ì•ˆ", "ì‚¬ë‘"]
        # ê¸°ì¡´ íš¨ê³¼ì ì¸ ë‹¨ì–´ë“¤
        effective_words = ["ì‚¬ëŒ", "ìˆœì„œ", "ê³µê°„", "ì§€ì—­", "ì˜ì—­", "ê³¼ì •", "ì ˆì°¨", "ìˆ˜ë‹¨"]
        # ì¼ë°˜ íƒìƒ‰ ë‹¨ì–´ë“¤
        general_words = ["ì‹œê°„", "ìì—°", "ìŒì‹", "ê°ì •", "ì¥ì†Œ", "í–‰ë™", "ìƒê°", "ë¬¸ì œ", "ì„¸ìƒ", 
                        "ì‚¬íšŒ", "êµìœ¡", "ì •ì¹˜", "ê²½ì œ", "ë¬¸í™”", "ê³¼í•™", "ì˜ˆìˆ ", "ê±´ê°•"]
        
        # ëª¨ë“  ë‹¨ì–´ë¥¼ ìš°ì„ ìˆœìœ„ì— ë”°ë¼ ê²°í•©
        initial_words = high_impact_words + effective_words + general_words
        
        for word in initial_words:
            if word in vocab and word not in tried_words:
                score = 0
                
                # 1. í•™ìŠµëœ í‰ê·  ìœ ì‚¬ë„
                if word in word_frequency:
                    freq_data = word_frequency[word]
                    avg_sim = freq_data.get('avg_similarity', 0)
                    count = freq_data.get('count', 0)
                    
                    # ìì£¼ ì‚¬ìš©ë˜ê³  í‰ê·  ìœ ì‚¬ë„ê°€ ë†’ì€ ë‹¨ì–´ ì„ í˜¸
                    score = avg_sim * math.log(count + 1) * 10
                else:
                    # ìƒˆë¡œìš´ ë‹¨ì–´ë„ íƒìƒ‰ ê°€ì¹˜ ë¶€ì—¬
                    score = 0.5
                
                # 2. ê³ ì˜í–¥ ë‹¨ì–´ ë³´ë„ˆìŠ¤
                if word in high_impact_words:
                    score += 50  # ê³ ì˜í–¥ ë‹¨ì–´ì— í° ë³´ë„ˆìŠ¤
                elif word in effective_words:
                    score += 20  # íš¨ê³¼ì ì¸ ë‹¨ì–´ì— ì¤‘ê°„ ë³´ë„ˆìŠ¤
                
                initial_candidates.append((word, score))
        
        if initial_candidates:
            # ì ìˆ˜ìˆœ ì •ë ¬í•˜ë˜ ìƒìœ„ 3ê°œ ì¤‘ í™•ë¥ ì  ì„ íƒ (ë‹¤ì–‘ì„± ìœ ì§€)
            initial_candidates.sort(key=lambda x: x[1], reverse=True)
            top_candidates = initial_candidates[:3]
            
            # ê°€ì¤‘ì¹˜ ê¸°ë°˜ í™•ë¥ ì  ì„ íƒ
            total_score = sum(c[1] for c in top_candidates)
            if total_score > 0:
                probabilities = [c[1] / total_score for c in top_candidates]
                selected_idx = random.choices(range(len(top_candidates)), weights=probabilities)[0]
                return top_candidates[selected_idx][0]
            else:
                return top_candidates[0][0]
        
        # í›„ë³´ê°€ ì—†ìœ¼ë©´ ì–´íœ˜ì—ì„œ ëœë¤ ì„ íƒ
        available = [w for w in vocab if w not in tried_words]
        return random.choice(available) if available else None
    
    def _explore_derivatives(self, session: GameSession, vocab: List[str]) -> Optional[str]:
        """
        ê¸°ì¡´ ë‹¨ì–´ë“¤ì˜ íŒŒìƒì–´ë¥¼ íƒìƒ‰í•©ë‹ˆë‹¤.
        
        Args:
            session (GameSession): í˜„ì¬ ê²Œì„ ì„¸ì…˜
            vocab (List[str]): ì‚¬ìš© ê°€ëŠ¥í•œ ì–´íœ˜ ëª©ë¡
            
        Returns:
            Optional[str]: ì„ íƒëœ íŒŒìƒì–´
        """
        derivatives = []
        
        # ê¸°ì¡´ ì¶”ì¸¡ì—ì„œ ì–´ê·¼ ê¸°ë°˜ íŒŒìƒì–´ ìƒì„±
        for guess in session.guesses:
            word = guess.word
            if len(word) > 1:
                root = word[:-1]  # ë§ˆì§€ë§‰ ê¸€ì ì œê±°
                
                # ê°™ì€ ì–´ê·¼ì„ ê°€ì§„ ë‹¨ì–´ë“¤ ì°¾ê¸°
                for vocab_word in vocab:
                    if (vocab_word.startswith(root) and 
                        vocab_word != word and 
                        vocab_word not in session.tried_words and 
                        len(vocab_word) <= len(word) + 2):
                        
                        # ì˜ˆìƒ ìœ ì‚¬ë„ ì°¨ì´ ê³„ì‚° (ì‘ì„ìˆ˜ë¡ ì¢‹ìŒ)
                        expected_diff = abs(guess.similarity - 0.1)
                        derivatives.append((vocab_word, expected_diff))
        
        if derivatives:
            # ìœ ì‚¬ë„ê°€ ë†’ì„ ê²ƒìœ¼ë¡œ ì˜ˆìƒë˜ëŠ” ìˆœìœ¼ë¡œ ì •ë ¬
            derivatives.sort(key=lambda x: x[1])
            selected_word = derivatives[0][0]
            # print(f"   ğŸ¯ íŒŒìƒì–´ íƒìƒ‰: '{selected_word}'")  # ë¡œê·¸ ì œê±°
            return selected_word
        
        # íŒŒìƒì–´ë„ ì—†ìœ¼ë©´ ëœë¤ ì„ íƒ
        available_words = [w for w in vocab if w not in session.tried_words]
        if available_words:
            return random.choice(available_words)
        
        return None
    
    def get_strategy_name(self) -> str:
        return "ë„“ì€ì˜ë¯¸íƒìƒ‰"
    
    def _get_learning_based_candidates(self, vocab: List[str], learned_data: Dict, 
                                     tried_words: Set[str], limit: int = 10) -> List[str]:
        """
        í•™ìŠµ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ íš¨ê³¼ì ì¸ í›„ë³´ ë‹¨ì–´ë“¤ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
        
        Args:
            vocab (List[str]): ì‚¬ìš© ê°€ëŠ¥í•œ ì–´íœ˜
            learned_data (Dict): í•™ìŠµëœ ë°ì´í„°
            tried_words (Set[str]): ì´ë¯¸ ì‹œë„í•œ ë‹¨ì–´ë“¤
            limit (int): ë°˜í™˜í•  ìµœëŒ€ ë‹¨ì–´ ìˆ˜
            
        Returns:
            List[str]: ì¶”ì²œ ë‹¨ì–´ ëª©ë¡
        """
        word_frequency = learned_data.get('word_frequency', {})
        candidates = []
        
        # í•™ìŠµëœ ë‹¨ì–´ë“¤ ì¤‘ì—ì„œ íš¨ê³¼ì ì¸ ê²ƒë“¤ ì„ íƒ
        for word, freq_data in word_frequency.items():
            if word in vocab and word not in tried_words:
                # í‰ê·  ìœ ì‚¬ë„ê°€ ë†’ê³  ì„±ê³µ ê²½í—˜ì´ ìˆëŠ” ë‹¨ì–´
                if freq_data['avg_similarity'] > 30 and freq_data['count'] >= 2:
                    effectiveness = freq_data['avg_similarity'] * math.log(freq_data['count'] + 1)
                    candidates.append((word, effectiveness))
        
        # íš¨ê³¼ì„± ìˆœìœ¼ë¡œ ì •ë ¬
        candidates.sort(key=lambda x: x[1], reverse=True)
        return [word for word, _ in candidates[:limit]]


class SemanticGradientSearch(SearchStrategy):
    """
    2ë‹¨ê³„: ì˜ë¯¸ì  ê²½ì‚¬ íƒìƒ‰ ì „ëµ
    ê³ ì„±ëŠ¥ ì•µì»¤ ë‹¨ì–´ë“¤ì„ ê¸°ë°˜ìœ¼ë¡œ ì˜ë¯¸ì  ê²½ì‚¬ë¥¼ ë”°ë¼ íƒìƒ‰í•©ë‹ˆë‹¤.
    """
    
    def __init__(self):
        """ì˜ë¯¸ì  í™•ì¥ ê·œì¹™ë“¤ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        # ì–¸ì–´í•™ì  ì—°ê´€ì–´ ê·¸ë£¹
        self.linguistic_associations = {
            "ë¬¸ì œ": ["ê³¼ì œ", "ìŸì ", "ì´ìŠˆ", "ê³ ë¯¼", "ê±±ì •", "ë‚œì œ"],
            "í•´ê²°": ["ì²˜ë¦¬", "í•´ë‹µ", "ë°©ì•ˆ", "ëŒ€ì•ˆ", "ê·¹ë³µ", "ì™„ë£Œ"],
            "ì¤‘ìš”": ["í•µì‹¬", "ì£¼ìš”", "í•„ìˆ˜", "ê¸°ë³¸", "ê·¼ë³¸", "ë³¸ì§ˆ"],
            "ë³€í™”": ["ì „í™˜", "ê°œì„ ", "ë°œì „", "ì§„ë³´", "ì„±ì¥", "í˜ì‹ "],
            "ê´€ê³„": ["ì—°ê²°", "ê²°í•©", "ì†Œí†µ", "êµë¥˜", "ìƒí˜¸ì‘ìš©", "í˜‘ë ¥"]
        }
        
        # ë¬¸ë§¥ì  ê´€ë ¨ì–´ ë§¤í•‘
        self.contextual_maps = {
            # ì‚¬íšŒ/ì •ì¹˜ ë¬¸ë§¥
            "ì‚¬íšŒ": ["ì •ì¹˜", "ê²½ì œ", "ë¬¸í™”", "êµìœ¡", "ë³µì§€", "ì œë„"],
            "êµ­ë¯¼": ["ì‹œë¯¼", "ì£¼ë¯¼", "ì¸ë¯¼", "êµ­ê°€", "ì •ë¶€", "ê³µë™ì²´"],
            
            # êµìœ¡/í•™ìŠµ ë¬¸ë§¥
            "í•™ìŠµ": ["êµìœ¡", "ê³µë¶€", "ì—°êµ¬", "ì§€ì‹", "ì´í•´", "ìŠµë“"],
            "ì§€ì‹": ["ì •ë³´", "í•™ë¬¸", "ê²½í—˜", "ê¸°ìˆ ", "ëŠ¥ë ¥", "ì‹¤ë ¥"],
            
            # ê°ì •/ì‹¬ë¦¬ ë¬¸ë§¥
            "ê°ì •": ["ë§ˆìŒ", "ê¸°ë¶„", "ëŠë‚Œ", "ì •ì„œ", "ì‹¬ë¦¬", "ì˜ì‹"],
            "í–‰ë³µ": ["ê¸°ì¨", "ë§Œì¡±", "ì¦ê±°ì›€", "ì›ƒìŒ", "í‰í™”", "ì‚¬ë‘"]
        }
    
    def select_word(self, session: GameSession, vocab: List[str], 
                   learned_data: Dict) -> Optional[str]:
        """
        ìƒìœ„ ìœ ì‚¬ë„ ë‹¨ì–´ë“¤ì„ ê¸°ë°˜ìœ¼ë¡œ ì˜ë¯¸ì  ê²½ì‚¬ë¥¼ ë”°ë¼ íƒìƒ‰í•©ë‹ˆë‹¤.
        
        Args:
            session (GameSession): í˜„ì¬ ê²Œì„ ì„¸ì…˜
            vocab (List[str]): ì‚¬ìš© ê°€ëŠ¥í•œ ì–´íœ˜ ëª©ë¡
            learned_data (Dict): í•™ìŠµëœ ë°ì´í„°
            
        Returns:
            Optional[str]: ì„ íƒëœ ë‹¨ì–´
        """
        # ìƒìœ„ 3ê°œ ì¶”ì¸¡ ì„ íƒ
        top_guesses = session.get_top_guesses(3)
        
        # ì—¬ëŸ¬ ë°©í–¥ìœ¼ë¡œ ë™ì‹œ íƒìƒ‰
        all_candidates = []
        
        for guess in top_guesses:
            # 1. ì˜ë¯¸ì  í™•ì¥
            expansions = self._get_semantic_expansions(guess.word, vocab, session.tried_words)
            all_candidates.extend(expansions)
            
            # 2. ì—°ê´€ì–´ íƒìƒ‰
            associations = self._get_semantic_associations(guess.word, vocab, session.tried_words)
            all_candidates.extend(associations)
            
            # 3. ë¬¸ë§¥ì  ê´€ë ¨ì–´
            contextual = self._get_contextual_relations(guess.word, vocab, session.tried_words)
            all_candidates.extend(contextual)
        
        # ì¤‘ë³µ ì œê±° ë° ë™ì  ì ìˆ˜ ê¸°ë°˜ ì„ íƒ
        unique_candidates = list(set(all_candidates))
        if unique_candidates:
            scored_candidates = self._score_candidates(
                unique_candidates, session, learned_data)
            
            if scored_candidates:
                selected_word = scored_candidates[0][0]
                # print(f"   ğŸ¯ ì˜ë¯¸ì  ë°©í–¥ íƒìƒ‰: '{selected_word}' (ì ìˆ˜: {scored_candidates[0][1]:.2f})")  # ë¡œê·¸ ì œê±°
                return selected_word
        
        # í›„ë³´ê°€ ì—†ìœ¼ë©´ Wide íƒìƒ‰ìœ¼ë¡œ ë³µê·€
        wide_strategy = WideSemanticExploration()
        return wide_strategy.select_word(session, vocab, learned_data)
    
    def _get_semantic_expansions(self, word: str, vocab: List[str], 
                               tried_words: Set[str]) -> List[str]:
        """
        ë‹¨ì–´ì˜ ì˜ë¯¸ì  í™•ì¥ì–´ë“¤ì„ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            word (str): ê¸°ì¤€ ë‹¨ì–´
            vocab (List[str]): ì‚¬ìš© ê°€ëŠ¥í•œ ì–´íœ˜
            tried_words (Set[str]): ì´ë¯¸ ì‹œë„í•œ ë‹¨ì–´ë“¤
            
        Returns:
            List[str]: í™•ì¥ì–´ ëª©ë¡
        """
        expansions = []
        
        # ì–´ê·¼ ê¸°ë°˜ í™•ì¥ (ì• 2ê¸€ì ì–´ê·¼)
        if len(word) > 2:
            root = word[:2]
            for vocab_word in vocab:
                if (vocab_word.startswith(root) and 
                    vocab_word != word and 
                    vocab_word not in tried_words):
                    expansions.append(vocab_word)
        
        # ì˜ë¯¸ ì˜ì—­ë³„ í™•ì¥
        semantic_expansions = {
            "ì‚¬ëŒ": ["ì¸ê°„", "ê°œì¸", "íƒ€ì¸", "ëˆ„êµ°ê°€", "ì‚¬ëŒë“¤", "ì¸ë¬¼", "ì¸ì‚¬"],
            "ì‹œê°„": ["ë•Œ", "ìˆœê°„", "ì‹œê¸°", "ì‹œì ˆ", "ê¸°ê°„", "ì‹œì ", "ì‹œëŒ€"],
            "ì¥ì†Œ": ["ê³³", "ì§€ì—­", "ìœ„ì¹˜", "ê³µê°„", "ì˜ì—­", "ë²”ìœ„", "ì˜í† "],
            "ë°©ë²•": ["ìˆ˜ë‹¨", "ë°©ì‹", "ê¸°ë²•", "ì ˆì°¨", "ê³¼ì •", "ë‹¨ê³„"],
            "ìƒíƒœ": ["ì¡°ê±´", "ìƒí™©", "í™˜ê²½", "ë¶„ìœ„ê¸°", "ëŠë‚Œ", "ê¸°ë¶„"],
            "í–‰ë™": ["í™œë™", "ì›€ì§ì„", "ì‘ì—…", "í–‰ìœ„", "ì‹¤í–‰", "ì§„í–‰"]
        }
        
        # í•´ë‹¹ ë²”ì£¼ì— ì†í•˜ëŠ” ê²½ìš° ê°™ì€ ë²”ì£¼ì˜ ë‹¤ë¥¸ ë‹¨ì–´ë“¤ ì¶”ê°€
        for category, words in semantic_expansions.items():
            if word in words:
                for expansion_word in words:
                    if (expansion_word != word and 
                        expansion_word in vocab and 
                        expansion_word not in tried_words):
                        expansions.append(expansion_word)
        
        return expansions[:10]  # ìµœëŒ€ 10ê°œë¡œ ì œí•œ
    
    def _get_semantic_associations(self, word: str, vocab: List[str], 
                                 tried_words: Set[str]) -> List[str]:
        """
        ë‹¨ì–´ì˜ ì˜ë¯¸ì  ì—°ê´€ì–´ë“¤ì„ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            word (str): ê¸°ì¤€ ë‹¨ì–´
            vocab (List[str]): ì‚¬ìš© ê°€ëŠ¥í•œ ì–´íœ˜
            tried_words (Set[str]): ì´ë¯¸ ì‹œë„í•œ ë‹¨ì–´ë“¤
            
        Returns:
            List[str]: ì—°ê´€ì–´ ëª©ë¡
        """
        associations = []
        
        # ì–¸ì–´í•™ì  ì—°ê´€ì–´ ê²€ìƒ‰
        for key, words in self.linguistic_associations.items():
            if word == key or word in words:
                for assoc_word in words:
                    if (assoc_word != word and 
                        assoc_word in vocab and 
                        assoc_word not in tried_words):
                        associations.append(assoc_word)
        
        return associations[:8]  # ìµœëŒ€ 8ê°œë¡œ ì œí•œ
    
    def _get_contextual_relations(self, word: str, vocab: List[str], 
                                tried_words: Set[str]) -> List[str]:
        """
        ë‹¨ì–´ì˜ ë¬¸ë§¥ì  ê´€ë ¨ì–´ë“¤ì„ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            word (str): ê¸°ì¤€ ë‹¨ì–´
            vocab (List[str]): ì‚¬ìš© ê°€ëŠ¥í•œ ì–´íœ˜
            tried_words (Set[str]): ì´ë¯¸ ì‹œë„í•œ ë‹¨ì–´ë“¤
            
        Returns:
            List[str]: ë¬¸ë§¥ì  ê´€ë ¨ì–´ ëª©ë¡
        """
        relations = []
        
        # ë¬¸ë§¥ì  ê´€ë ¨ì–´ ê²€ìƒ‰
        for key, words in self.contextual_maps.items():
            if word == key or word in words:
                for rel_word in words:
                    if (rel_word != word and 
                        rel_word in vocab and 
                        rel_word not in tried_words):
                        relations.append(rel_word)
        
        return relations[:6]  # ìµœëŒ€ 6ê°œë¡œ ì œí•œ
    
    def _sort_by_effectiveness(self, candidates: List[str], 
                             word_frequency: Dict) -> List[str]:
        """
        í•™ìŠµëœ íš¨ê³¼ì„±ì— ë”°ë¼ í›„ë³´ë“¤ì„ ì •ë ¬í•©ë‹ˆë‹¤.
        
        Args:
            candidates (List[str]): í›„ë³´ ë‹¨ì–´ë“¤
            word_frequency (Dict): ë‹¨ì–´ ë¹ˆë„ ë°ì´í„°
            
        Returns:
            List[str]: íš¨ê³¼ì„± ìˆœìœ¼ë¡œ ì •ë ¬ëœ í›„ë³´ë“¤
        """
        def get_effectiveness_score(word: str) -> float:
            if word in word_frequency:
                freq_data = word_frequency[word]
                return freq_data.get('avg_similarity', 0) * freq_data.get('count', 1)
            return 0
        
        candidates.sort(key=get_effectiveness_score, reverse=True)
        return candidates
    
    def _score_candidates(self, candidates: List[str], session: GameSession, 
                         learned_data: Dict) -> List[Tuple[str, float]]:
        """
        ì—¬ëŸ¬ ìš”ì†Œë¥¼ ê³ ë ¤í•˜ì—¬ í›„ë³´ ë‹¨ì–´ë“¤ì— ì ìˆ˜ë¥¼ ë¶€ì—¬í•©ë‹ˆë‹¤.
        
        Args:
            candidates (List[str]): í›„ë³´ ë‹¨ì–´ë“¤
            session (GameSession): í˜„ì¬ ê²Œì„ ì„¸ì…˜
            learned_data (Dict): í•™ìŠµëœ ë°ì´í„°
            
        Returns:
            List[Tuple[str, float]]: (ë‹¨ì–´, ì ìˆ˜) íŠœí”Œì˜ ì •ë ¬ëœ ë¦¬ìŠ¤íŠ¸
        """
        word_frequency = learned_data.get('word_frequency', {})
        word_pairs = learned_data.get('word_pairs', {})
        
        scored = []
        for word in candidates:
            score = 0
            
            # 1. ê¸°ë³¸ íš¨ê³¼ì„± ì ìˆ˜
            if word in word_frequency:
                freq_data = word_frequency[word]
                avg_sim = freq_data.get('avg_similarity', 0)
                count = freq_data.get('count', 0)
                score += avg_sim * math.log(count + 1) * 5
            
            # 2. ìµœê·¼ ê³ ë“ì  ë‹¨ì–´ì™€ì˜ ê´€ê³„
            top_guesses = session.get_top_guesses(3)
            for guess in top_guesses:
                pair_key1 = f"{guess.word}|{word}"
                pair_key2 = f"{word}|{guess.word}"
                
                if pair_key1 in word_pairs or pair_key2 in word_pairs:
                    pair_data = word_pairs.get(pair_key1, word_pairs.get(pair_key2, {}))
                    similarity_diffs = pair_data.get('similarity_diffs', [])
                    if similarity_diffs:
                        avg_diff = sum(similarity_diffs) / len(similarity_diffs)
                        # ìœ ì‚¬ë„ ì°¨ì´ê°€ ì‘ì„ìˆ˜ë¡ ë†’ì€ ì ìˆ˜
                        score += (1 - avg_diff/100) * guess.similarity * 3
            
            # 3. ì˜ë¯¸ì  ê±°ë¦¬ ì ìˆ˜ (ì–´ê·¼ ê³µìœ  ë“±)
            for guess in session.guesses[-5:]:  # ìµœê·¼ 5ê°œ
                if len(word) > 2 and len(guess.word) > 2:
                    # ê³µí†µ ì–´ê·¼ ê¸¸ì´
                    common_prefix_len = 0
                    for i in range(min(len(word), len(guess.word))):
                        if word[i] == guess.word[i]:
                            common_prefix_len += 1
                        else:
                            break
                    
                    if common_prefix_len >= 2:
                        score += guess.similarity * common_prefix_len
            
            # 4. ë‹¤ì–‘ì„± ë³´ë„ˆìŠ¤ (ë„ˆë¬´ ë¹„ìŠ·í•œ ë‹¨ì–´ ì—°ì† ì‹œë„ ë°©ì§€)
            recent_words = [g.word for g in session.guesses[-3:]]
            if recent_words:
                avg_similarity_to_recent = 0
                for recent in recent_words:
                    if len(word) > 2 and len(recent) > 2:
                        common_chars = set(word) & set(recent)
                        avg_similarity_to_recent += len(common_chars) / max(len(word), len(recent))
                
                avg_similarity_to_recent /= len(recent_words)
                # ì ë‹¹í•œ ì°¨ì´ê°€ ìˆìœ¼ë©´ ë³´ë„ˆìŠ¤
                if 0.2 < avg_similarity_to_recent < 0.7:
                    score += 1
            
            scored.append((word, score))
        
        # ì ìˆ˜ìˆœ ì •ë ¬
        scored.sort(key=lambda x: x[1], reverse=True)
        return scored
    
    def get_strategy_name(self) -> str:
        return "ì˜ë¯¸ì ê²½ì‚¬íƒìƒ‰"


class FocusedSemanticSearch(SearchStrategy):
    """
    3ë‹¨ê³„: ì§‘ì¤‘ ì˜ë¯¸ íƒìƒ‰ ì „ëµ
    ê³ ìœ ì‚¬ë„ ì˜ì—­ ì£¼ë³€ì—ì„œ ë‹¤ì¸µ ì—°ê´€ì„ ì‚¬ìš©í•˜ì—¬ ì§‘ì¤‘ì ìœ¼ë¡œ íƒìƒ‰í•©ë‹ˆë‹¤.
    """
    
    def __init__(self):
        """ì˜ë¯¸ ì˜ì—­ë³„ ë‹¨ì–´ ê·¸ë£¹ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        self.semantic_fields = {
            "ì •ì¹˜ì‚¬íšŒ": ["ì •ì¹˜", "ì‚¬íšŒ", "êµ­ê°€", "ì •ë¶€", "êµ­ë¯¼", "ì‹œë¯¼", "ê³µë™ì²´", "ì‚¬íšŒì ", "ì •ì±…", "ì œë„"],
            "êµìœ¡í•™ìŠµ": ["êµìœ¡", "í•™ìŠµ", "ê³µë¶€", "ì§€ì‹", "í•™ë¬¸", "ì—°êµ¬", "ì´í•´", "ìŠµë“", "ê²½í—˜"],
            "ê°ì •ì‹¬ë¦¬": ["ê°ì •", "ë§ˆìŒ", "ê¸°ë¶„", "ëŠë‚Œ", "ì •ì„œ", "ì‹¬ë¦¬", "ì‚¬ë‘", "í–‰ë³µ", "ìŠ¬í””"],
            "ì‹œê³µê°„": ["ì‹œê°„", "ê³µê°„", "ì¥ì†Œ", "ìœ„ì¹˜", "ë•Œ", "ìˆœê°„", "ì§€ì—­", "ì˜ì—­", "ë²”ìœ„"],
            "í–‰ë™í™œë™": ["í–‰ë™", "í™œë™", "ì›€ì§ì„", "ì‘ì—…", "ì‹¤í–‰", "ì§„í–‰", "ê³¼ì •", "ë°©ë²•"]
        }
    
    def select_word(self, session: GameSession, vocab: List[str], 
                   learned_data: Dict) -> Optional[str]:
        """
        ê³ ìœ ì‚¬ë„ ë‹¨ì–´ë“¤ì˜ ê³µí†µ ì˜ë¯¸ ì˜ì—­ì—ì„œ ì§‘ì¤‘ì ìœ¼ë¡œ íƒìƒ‰í•©ë‹ˆë‹¤.
        
        Args:
            session (GameSession): í˜„ì¬ ê²Œì„ ì„¸ì…˜
            vocab (List[str]): ì‚¬ìš© ê°€ëŠ¥í•œ ì–´íœ˜ ëª©ë¡
            learned_data (Dict): í•™ìŠµëœ ë°ì´í„°
            
        Returns:
            Optional[str]: ì„ íƒëœ ë‹¨ì–´
        """
        # ìƒìœ„ 2ê°œ ì¶”ì¸¡ ë¶„ì„
        top_guesses = session.get_top_guesses(2)
        
        # ê³µí†µ ì˜ë¯¸ ì˜ì—­ ì°¾ê¸°
        common_field = self._find_common_semantic_field([g.word for g in top_guesses])
        
        if common_field:
            candidates = [w for w in common_field 
                         if w in vocab and w not in session.tried_words]
            if candidates:
                selected_word = candidates[0]
                print(f"   ğŸ¯ ê³µí†µ ì˜ë¯¸ ì˜ì—­: '{selected_word}'")
                return selected_word
        
        # ìµœê³  ë‹¨ì–´ ì£¼ë³€ ë‹¤ì¸µ íƒìƒ‰
        if session.guesses:
            best_guess = max(session.guesses, key=lambda g: g.similarity)
            
            # 1ì¸µ: ì§ì ‘ ì—°ê´€ì–´
            gradient_strategy = SemanticGradientSearch()
            layer1 = gradient_strategy._get_semantic_associations(
                best_guess.word, vocab, session.tried_words)
            
            # 2ì¸µ: 1ì¸µ ë‹¨ì–´ë“¤ì˜ ì—°ê´€ì–´
            layer2 = []
            for word in layer1[:3]:  # ìƒìœ„ 3ê°œë§Œ
                if word not in session.tried_words:
                    layer2.extend(gradient_strategy._get_semantic_associations(
                        word, vocab, session.tried_words))
            
            # ëª¨ë“  í›„ë³´ ê²°í•©
            all_candidates = layer1 + layer2
            unique_candidates = [w for w in set(all_candidates) 
                               if w in vocab and w not in session.tried_words]
            
            if unique_candidates:
                # ë™ì  ì ìˆ˜ ê¸°ë°˜ ì„ íƒ
                scored_candidates = self._score_focused_candidates(
                    unique_candidates, best_guess, session, learned_data)
                
                if scored_candidates:
                    selected_word = scored_candidates[0][0]
                    print(f"   ğŸ¯ '{best_guess.word}' ë‹¤ì¸µ ì—°ê´€ì–´: '{selected_word}'")
                    return selected_word
        
        # ì‹¤íŒ¨ ì‹œ ê²½ì‚¬ íƒìƒ‰ìœ¼ë¡œ ë³µê·€
        gradient_strategy = SemanticGradientSearch()
        return gradient_strategy.select_word(session, vocab, learned_data)
    
    def _find_common_semantic_field(self, words: List[str]) -> List[str]:
        """
        ë‹¨ì–´ë“¤ì˜ ê³µí†µ ì˜ë¯¸ ì˜ì—­ì„ ì°¾ìŠµë‹ˆë‹¤.
        
        Args:
            words (List[str]): ë¶„ì„í•  ë‹¨ì–´ë“¤
            
        Returns:
            List[str]: ê³µí†µ ì˜ë¯¸ ì˜ì—­ì˜ ë‹¨ì–´ë“¤
        """
        if len(words) < 2:
            return []
        
        # ëª¨ë“  ë‹¨ì–´ê°€ ì†í•˜ëŠ” ì˜ë¯¸ ì˜ì—­ ì°¾ê¸°
        for field_name, field_words in self.semantic_fields.items():
            # ëª¨ë“  ì…ë ¥ ë‹¨ì–´ê°€ ì´ ì˜ì—­ì— ì†í•˜ëŠ”ì§€ í™•ì¸
            if all(any(word in field_words or word.startswith(fw[:2]) 
                      for fw in field_words) for word in words):
                # ì…ë ¥ ë‹¨ì–´ë“¤ì„ ì œì™¸í•œ ë‚˜ë¨¸ì§€ ë°˜í™˜
                return [w for w in field_words if w not in words]
        
        return []
    
    def _score_focused_candidates(self, candidates: List[str], best_guess: GuessResult,
                                session: GameSession, learned_data: Dict) -> List[Tuple[str, float]]:
        """
        ì§‘ì¤‘ íƒìƒ‰ì„ ìœ„í•œ í›„ë³´ ì ìˆ˜ ê³„ì‚°
        
        Args:
            candidates (List[str]): í›„ë³´ ë‹¨ì–´ë“¤
            best_guess (GuessResult): í˜„ì¬ ìµœê³  ìœ ì‚¬ë„ ë‹¨ì–´
            session (GameSession): í˜„ì¬ ê²Œì„ ì„¸ì…˜  
            learned_data (Dict): í•™ìŠµëœ ë°ì´í„°
            
        Returns:
            List[Tuple[str, float]]: (ë‹¨ì–´, ì ìˆ˜) íŠœí”Œì˜ ì •ë ¬ëœ ë¦¬ìŠ¤íŠ¸
        """
        word_pairs = learned_data.get('word_pairs', {})
        scored = []
        
        for word in candidates:
            score = 0
            
            # 1. ìµœê³  ë‹¨ì–´ì™€ì˜ í•™ìŠµëœ ê´€ê³„
            pair_key1 = f"{best_guess.word}|{word}"
            pair_key2 = f"{word}|{best_guess.word}"
            
            if pair_key1 in word_pairs or pair_key2 in word_pairs:
                pair_data = word_pairs.get(pair_key1, word_pairs.get(pair_key2, {}))
                similarity_diffs = pair_data.get('similarity_diffs', [])
                if similarity_diffs:
                    avg_diff = sum(similarity_diffs) / len(similarity_diffs)
                    # ë§¤ìš° ìœ ì‚¬í•œ ê´€ê³„ë©´ ë†’ì€ ì ìˆ˜ (0-100 scale)
                    if avg_diff < 5:
                        score += 10 * (1 - avg_diff/100)
            
            # 2. ìœ ì‚¬ë„ ê¸°ìš¸ê¸° ì˜ˆì¸¡
            recent_guesses = session.guesses[-5:]
            if len(recent_guesses) >= 2:
                # ìµœê·¼ ìœ ì‚¬ë„ ë³€í™”ìœ¨ ê³„ì‚°
                similarities = [g.similarity for g in recent_guesses]
                gradient = (similarities[-1] - similarities[0]) / len(similarities)
                
                # ì–‘ì˜ ê¸°ìš¸ê¸°ë©´ ë” ë†’ì€ ì ìˆ˜
                if gradient > 0:
                    score += gradient * 5
            
            # 3. ì˜ë¯¸ì  ê·¼ì ‘ì„±
            if len(word) > 2 and len(best_guess.word) > 2:
                # ê³µí†µ ë¬¸ì ë¹„ìœ¨
                common_chars = set(word) & set(best_guess.word)
                char_similarity = len(common_chars) / max(len(word), len(best_guess.word))
                score += char_similarity * best_guess.similarity * 3
            
            scored.append((word, score))
        
        scored.sort(key=lambda x: x[1], reverse=True)
        return scored
    
    def get_strategy_name(self) -> str:
        return "ì§‘ì¤‘ì˜ë¯¸íƒìƒ‰"


class PrecisionSemanticSearch(SearchStrategy):
    """
    4ë‹¨ê³„: ì •ë°€ ì˜ë¯¸ íƒìƒ‰ ì „ëµ
    í˜•íƒœë¡ ì  ë¶„ì„ì„ ì‚¬ìš©í•˜ì—¬ ê³ ìœ ì‚¬ë„ ìƒí™©ì—ì„œ ì •ë°€í•˜ê²Œ íƒìƒ‰í•©ë‹ˆë‹¤.
    """
    
    def select_word(self, session: GameSession, vocab: List[str], 
                   learned_data: Dict) -> Optional[str]:
        """
        í˜•íƒœë¡ ì  ë³€í˜•ê³¼ í•™ìŠµëœ ì´ˆê·¼ì ‘ ë‹¨ì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì •ë°€ íƒìƒ‰í•©ë‹ˆë‹¤.
        
        Args:
            session (GameSession): í˜„ì¬ ê²Œì„ ì„¸ì…˜
            vocab (List[str]): ì‚¬ìš© ê°€ëŠ¥í•œ ì–´íœ˜ ëª©ë¡
            learned_data (Dict): í•™ìŠµëœ ë°ì´í„°
            
        Returns:
            Optional[str]: ì„ íƒëœ ë‹¨ì–´
        """
        if not session.guesses:
            return None
        
        best_guess = max(session.guesses, key=lambda g: g.similarity)
        precision_candidates = []
        
        # 1. í˜•íƒœë¡ ì  ë³€í˜• ìƒì„±
        morphological_variants = self._generate_morphological_variants(
            best_guess.word, vocab, session.tried_words)
        precision_candidates.extend(morphological_variants[:3])
        
        # 2. í•™ìŠµëœ ì´ˆê·¼ì ‘ ë‹¨ì–´ë“¤
        word_pairs = learned_data.get('word_pairs', {})
        ultra_close_words = self._find_ultra_close_words(
            best_guess.word, word_pairs, vocab, session.tried_words)
        precision_candidates.extend([w[0] for w in ultra_close_words[:2]])
        
        if precision_candidates:
            selected_word = precision_candidates[0]
            print(f"   ğŸ¯ '{best_guess.word}' ì •ë°€ ë³€í˜•: '{selected_word}'")
            return selected_word
        
        # ì •ë°€ íƒìƒ‰ ì‹¤íŒ¨ ì‹œ ì§‘ì¤‘ íƒìƒ‰ìœ¼ë¡œ ë³µê·€
        focused_strategy = FocusedSemanticSearch()
        return focused_strategy.select_word(session, vocab, learned_data)
    
    def _generate_morphological_variants(self, word: str, vocab: List[str], 
                                       tried_words: Set[str]) -> List[str]:
        """
        ë‹¨ì–´ì˜ í˜•íƒœë¡ ì  ë³€í˜•ë“¤ì„ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            word (str): ê¸°ì¤€ ë‹¨ì–´
            vocab (List[str]): ì‚¬ìš© ê°€ëŠ¥í•œ ì–´íœ˜
            tried_words (Set[str]): ì´ë¯¸ ì‹œë„í•œ ë‹¨ì–´ë“¤
            
        Returns:
            List[str]: í˜•íƒœë¡ ì  ë³€í˜•ë“¤
        """
        variants = []
        
        if len(word) > 2:
            root = word[:-1]  # ë§ˆì§€ë§‰ ê¸€ì ì œê±°
            
            # í•œêµ­ì–´ ì¼ë°˜ì ì¸ ì ‘ë¯¸ì‚¬ë“¤
            suffixes = ['ë‹¤', 'í•˜ë‹¤', 'ë˜ë‹¤', 'ì´ë‹¤', 'ì ', 'ì˜', 'ë¡œ', 'ì„', 'ë¥¼']
            
            for suffix in suffixes:
                variant = root + suffix
                if (variant in vocab and 
                    variant not in tried_words and 
                    variant != word):
                    variants.append(variant)
        
        return variants
    
    def _find_ultra_close_words(self, word: str, word_pairs: Dict, 
                              vocab: List[str], tried_words: Set[str]) -> List[Tuple[str, float]]:
        """
        í•™ìŠµëœ ë°ì´í„°ì—ì„œ ì´ˆê·¼ì ‘ ë‹¨ì–´ë“¤ì„ ì°¾ìŠµë‹ˆë‹¤.
        
        Args:
            word (str): ê¸°ì¤€ ë‹¨ì–´
            word_pairs (Dict): ë‹¨ì–´ ìŒ ë°ì´í„°
            vocab (List[str]): ì‚¬ìš© ê°€ëŠ¥í•œ ì–´íœ˜
            tried_words (Set[str]): ì´ë¯¸ ì‹œë„í•œ ë‹¨ì–´ë“¤
            
        Returns:
            List[Tuple[str, float]]: (ë‹¨ì–´, í‰ê· ì°¨ì´) íŠœí”Œì˜ ë¦¬ìŠ¤íŠ¸
        """
        ultra_close = []
        
        for pair_key, pair_data in word_pairs.items():
            word1, word2 = pair_key.split('|')
            
            if word1 == word or word2 == word:
                other_word = word2 if word1 == word else word1
                
                if (other_word in vocab and 
                    other_word not in tried_words):
                    
                    # í‰ê·  ìœ ì‚¬ë„ ì°¨ì´ ê³„ì‚°
                    similarity_diffs = pair_data.get('similarity_diffs', [])
                    if similarity_diffs:
                        avg_diff = sum(similarity_diffs) / len(similarity_diffs)
                        # ë§¤ìš° ìœ ì‚¬í•œ ë‹¨ì–´ë“¤ë§Œ (ì°¨ì´ < 3, 0-100 scale)
                        if avg_diff < 3:
                            ultra_close.append((other_word, avg_diff))
        
        # ìœ ì‚¬ë„ ì°¨ì´ ìˆœìœ¼ë¡œ ì •ë ¬ (ì‘ì€ ìˆœ)
        ultra_close.sort(key=lambda x: x[1])
        return ultra_close
    
    def get_strategy_name(self) -> str:
        return "ì •ë°€ì˜ë¯¸íƒìƒ‰"


class StrategyEngine:
    """
    ì „ëµ ì—”ì§„: ìƒí™©ì— ë”°ë¼ ì ì ˆí•œ íƒìƒ‰ ì „ëµì„ ì„ íƒí•˜ê³  ì‹¤í–‰í•©ë‹ˆë‹¤.
    """
    
    def __init__(self, enable_logging: bool = True):
        """
        ëª¨ë“  ì „ëµë“¤ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
        
        Args:
            enable_logging (bool): ë¡œê¹… í™œì„±í™” ì—¬ë¶€
        """
        self.strategies = {
            "wide": WideSemanticExploration(),
            "gradient": SemanticGradientSearch(),
            "focused": FocusedSemanticSearch(),
            "precision": PrecisionSemanticSearch()
        }
        self.logger = StrategyLogger() if enable_logging else None
        self.previous_strategy = None
    
    def select_strategy(self, session: GameSession) -> SearchStrategy:
        """
        í˜„ì¬ ìƒí™©ì— ë”°ë¼ ìµœì ì˜ ì „ëµì„ ì„ íƒí•©ë‹ˆë‹¤.
        
        Args:
            session (GameSession): í˜„ì¬ ê²Œì„ ì„¸ì…˜
            
        Returns:
            SearchStrategy: ì„ íƒëœ ì „ëµ ê°ì²´
        """
        best_similarity = session.get_best_similarity()
        is_stuck = session.is_stagnant()
        
        # ê°œì„ ëœ ì „ëµ ì„ íƒ ë¡œì§ (0-100 scale)
        # í˜„ì¬ ì „ëµê³¼ ì‹œë„ íšŸìˆ˜ í™•ì¸
        current_strategy_name = session.strategy_history[-1] if session.strategy_history else None
        attempts_with_current = 0
        if current_strategy_name:
            for i in range(len(session.strategy_history) - 1, -1, -1):
                if session.strategy_history[i] == current_strategy_name:
                    attempts_with_current += 1
                else:
                    break
        
        # ì „ëµ ì „í™˜ ì¡°ê±´
        force_switch = False
        if attempts_with_current > 20 and is_stuck:  # 20íšŒ ì´ìƒ ê°™ì€ ì „ëµìœ¼ë¡œ ì •ì²´
            force_switch = True
        
        if not session.guesses or best_similarity < 10:
            # ì´ˆê¸° íƒìƒ‰
            strategy = self.strategies["wide"]
        elif force_switch or (is_stuck and attempts_with_current > 10):
            # ê°•ì œ ì „í™˜ ë˜ëŠ” ì •ì²´ ìƒíƒœ
            if current_strategy_name:
                # ìˆœí™˜ ì „ëµ: wide -> gradient -> focused -> precision -> wide
                strategy_order = ["wide", "gradient", "focused", "precision"]
                current_idx = -1
                for i, s in enumerate(strategy_order):
                    if s in current_strategy_name.lower():
                        current_idx = i
                        break
                next_idx = (current_idx + 1) % len(strategy_order)
                strategy = self.strategies[strategy_order[next_idx]]
            else:
                strategy = self.strategies["gradient"]
        else:
            # ìœ ì‚¬ë„ ê¸°ë°˜ ì „ëµ ì„ íƒ with ë” ë™ì ì¸ ì „í™˜
            if best_similarity < 15:
                strategy = self.strategies["gradient"]
            elif best_similarity < 30:
                # ìµœê·¼ ì§„ì „ í™•ì¸
                if len(session.guesses) >= 5:
                    recent_sims = [g.similarity for g in session.guesses[-5:]]
                    improvement = recent_sims[-1] - recent_sims[0]
                    
                    if improvement > 15:  # ë¹ ë¥¸ ê°œì„ 
                        strategy = self.strategies["focused"]
                    elif improvement < 5:  # ëŠë¦° ê°œì„ 
                        strategy = self.strategies["wide"]  # ë‹¤ì‹œ ë„“ê²Œ íƒìƒ‰
                    else:
                        strategy = self.strategies["gradient"]
                else:
                    strategy = self.strategies["gradient"]
            elif best_similarity < 50:
                # ì¤‘ê°„ ë‹¨ê³„ì—ì„œëŠ” ë” ìì£¼ ì „ëµ ë³€ê²½
                if len(session.guesses) >= 3:
                    recent_improvement = session.guesses[-1].similarity - session.guesses[-3].similarity
                    if recent_improvement < 3:  # ê°œì„ ì´ ëŠë¦¼
                        strategy = self.strategies["gradient"]
                    else:
                        strategy = self.strategies["focused"]
                else:
                    strategy = self.strategies["focused"]
            else:
                # ë†’ì€ ìœ ì‚¬ë„ì—ì„œëŠ” ì •ë°€ íƒìƒ‰
                strategy = self.strategies["precision"]
        
        # ì „ëµ ë³€ê²½ ë¡œê¹…
        if self.logger and self.previous_strategy and self.previous_strategy != strategy:
            reason = "ì •ì²´ ìƒíƒœ" if is_stuck else f"ìœ ì‚¬ë„ ë³€í™” ({best_similarity:.3f})"
            self.logger.log_strategy_change(
                self.previous_strategy.get_strategy_name(),
                strategy.get_strategy_name(),
                reason,
                best_similarity
            )
        
        self.previous_strategy = strategy
        return strategy
    
    def select_next_word(self, session: GameSession, vocab: List[str], 
                        learned_data: Dict) -> Optional[str]:
        """
        ìƒí™©ì— ë§ëŠ” ì „ëµì„ ì„ íƒí•˜ê³  ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.
        
        Args:
            session (GameSession): í˜„ì¬ ê²Œì„ ì„¸ì…˜
            vocab (List[str]): ì‚¬ìš© ê°€ëŠ¥í•œ ì–´íœ˜ ëª©ë¡
            learned_data (Dict): í•™ìŠµëœ ë°ì´í„°
            
        Returns:
            Optional[str]: ì„ íƒëœ ë‹¨ì–´
        """
        strategy = self.select_strategy(session)
        session.update_strategy(strategy.get_strategy_name())
        
        return strategy.select_word(session, vocab, learned_data)